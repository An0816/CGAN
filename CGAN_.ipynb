{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN_.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "15cRdvnIikaCoZII2hmKgkfO9xMogCkGN",
      "authorship_tag": "ABX9TyM9hduYI9FOdSaNoNY2R6/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/An0816/CGAN/blob/main/CGAN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXXfsHTXSF-x"
      },
      "source": [
        "- Dropout 효과  \n",
        "  : overfitting 방지  \n",
        "  : 성능 향과    \n",
        "  : 앙상블 효과( 매번 다른 형태의 노드로 학습하기 때문에)  \n",
        "\n",
        "- One hot Encoding  \n",
        "  : 데이터를 수많은 0과 한개의 1로 데이터를 구별하는 것\n",
        "  : `scatter_(축, 새로 나타낼 인덱스, 새로 저장할 입력값)`  \n",
        "  : `unsqueeze()` = 특정 위치에 1인 차원을 추가   \n",
        "\n",
        "- `torch.randn()` : 평균이 0이고 std가 1인 가우시안 정규분포를 이용해서 생성   \n",
        "- `torch.randint()` : 주어진 범위 내에서 정규를 균등하게 생성  \n",
        "- torch.ones() : 주어진 사이즈의 1로 이루어진 텐서 생성   \n",
        "- torch.zeros() : 주어진 사이즈의 0으로 이루어진 텐서 생성  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeIxPKN8MbZf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvdp5oetNALl"
      },
      "source": [
        "train_img = datasets.MNIST(root = 'MNIST/', train = True,\n",
        "                           download = True, transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean = (0.5,), std = (0.5,))\n",
        "                           ]))\n",
        "batch_size = 100\n",
        "train_data = DataLoader(dataset = train_img, batch_size = 100, shuffle = True, drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC41oq8rPPw4"
      },
      "source": [
        "# fake image를 생성해야 하므로, 마지막 layer에서 784개의 값을 만들어 내도록 해야 함\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(110, 256), # 110 = noise + label\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(), # 노드를 무작위로 껐다 켰다 반복하는 것\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, x, y):\n",
        "        x = torch.cat((x, y), dim = 1) # concatenation\n",
        "        x = self.model(x) # forward propagation\n",
        "        return x\n",
        "\n",
        "# 어떤 데이터가 진짜인지 가짜인지를 판단해야 하므로 결과적으로 하나의 확률값을 만들어내야 함\n",
        "# 확률값으로 나타내야 하기 때문에 마지막에 Sigmoid함수 사용\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(794, 1024), # 이미지 하나가 784값을 가짐 + label(0~9 = 10개)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x, y):\n",
        "        x = torch.cat((x, y), dim = 1)\n",
        "        x = self.model(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77O9bQD1QLXU"
      },
      "source": [
        "def one_hot_vector(labels, C = 10):\n",
        "    one_hot = torch.FloatTensor(labels.size(0), C).zero_().to(device)\n",
        "    target = one_hot.scatter_(1, labels.unsqueeze(1), 1) # scatter_(dim, index, src)\n",
        "    target = Variable(target)\n",
        "    return target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrKOJMuXS6pr"
      },
      "source": [
        "batch_size = 100\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM7-GjEdS6xd"
      },
      "source": [
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "optim_G = torch.optim.Adam(G.parameters(), lr = 0.001)\n",
        "optim_D = torch.optim.Adam(D.parameters(), lr = 0.001)\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGqrVlHqS6za"
      },
      "source": [
        "# train\n",
        "total_batch = len(train_data) # 600\n",
        "\n",
        "for epoch in range(200):\n",
        "    avg_cost = [0, 0]\n",
        "    for x, y in train_data:\n",
        "        x = x.view(x.size(0), -1).to(device)\n",
        "        x_oh = one_hot_vector(y.to(device), 10)\n",
        "\n",
        "        z = torch.randn(batch_size, 100, device = device) # noise (random하게 noise 생성)\n",
        "        z_label = torch.randint(10, (batch_size,), device = device)\n",
        "        z_oh = one_hot_vector(z_label, 10)\n",
        "        fake_img = G(z, z_oh)\n",
        "\n",
        "        real = (torch.FloatTensor(x.size(0), 1).fill_(1.0)).to(device)\n",
        "        fake = (torch.FloatTensor(x.size(0), 1).fill_(0.0)).to(device)\n",
        "\n",
        "        # train Generator\n",
        "        optim_G.zero_grad()\n",
        "        g_cost = criterion(D(fake_img, z_oh), real) \n",
        "        g_cost.backward()\n",
        "        optim_G.step()\n",
        "\n",
        "        fake_img = fake_img.detach().to(device)\n",
        "        # train Discriminator\n",
        "        optim_D.zero_grad()\n",
        "        d_cost = criterion(D(torch.cat((x, z_img)), torch.cat((x_oh, z_oh))), torch.cat((real, fake)))\n",
        "        d_cost.backward()\n",
        "        optim_D.step()\n",
        "\n",
        "        avg_cost[0] += g_cost\n",
        "        avg_cost[1] += d_cost\n",
        "    avg_cost[0] /= total_batch\n",
        "    avg_cost[1] /= total_batch\n",
        "\n",
        "    if (epoch+1) % 10 == 0 or epoch < 10:\n",
        "        print(f\"Epoch : {epoch + 1}, Generator : {avg_cost[0]}, Discriminator : {avg_cost[1]}\")\n",
        "        z = torch.rand(100, 100, device = device)\n",
        "        label = torch.Tensor(100).fill_(0).long().to(device)\n",
        "        for i in range(10):\n",
        "            for j in range(10):\n",
        "                label[10*i+j] = j\n",
        "        z_oh = one_hot_vector(label, 10)\n",
        "        fake_img = G(z, z_oh)\n",
        "        fake_img = fake_img.reshape([100, 1, 28, 28])\n",
        "        img_grid = make_grid(fake_img, nrow = 10, normalize = True)\n",
        "        save_image(img_grid, \"/content/drive/MyDrive/Deep Learning/GAN/GAN Result/%d.png\"%(epoch+1))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}